{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import SpaceTokenizer as tkz\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"./reviews_crawler/review_texts\"\n",
    "texts = os.listdir(path)\n",
    "for text in texts:\n",
    "    if len(text) > 32:\n",
    "        os.remove(path + '/' + str(text))\n",
    "texts = [text for text in texts if len(text) <= 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tknzr = tkz()\n",
    "tokensCount = 0\n",
    "sentencesCount = 0\n",
    "for text in texts:\n",
    "    with open(path + '/' + str(text)) as _text:\n",
    "        with open(path + '/' + str(text) + \"_sentences\", 'w') as outSents:\n",
    "            originalText = _text.read()\n",
    "            sentences = sent_tokenize(originalText)\n",
    "            sentencesCount += len(list(sentences))\n",
    "            outSents.write('\\n'.join(sentences))\n",
    "            with open(path + '/' + str(text) + \"_tokens\", 'w') as outToks:\n",
    "                tokSents = []\n",
    "                for sent in sentences:\n",
    "                    try:\n",
    "                        sent = tknzr.span_tokenize(sent)\n",
    "                        tokensCount += len(list(sent))\n",
    "                        sent = ' '.join(\"%s,%s\" % t for t in sent)\n",
    "                        tokSents.append(sent)\n",
    "                    except ValueError:\n",
    "                        tokSents.append(\"None\")\n",
    "                outToks.write('\\n'.join(tok_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9706356"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokensCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350785"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencesCount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
